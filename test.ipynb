{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.result_loader import KinectResultLoader, ArbeResultLoader, OptitrackResultLoader\n",
    "import numpy as np\n",
    "import os\n",
    "root_path = \"/home/nesc525/chen/3DSVC/__test__/default\"\n",
    "\n",
    "arbe_loader = ArbeResultLoader(root_path)\n",
    "arbe_loader.file_dict['arbe'] = arbe_loader.file_dict['arbe'].drop_duplicates(subset=['dt'],keep='first')\n",
    "ids = arbe_loader.file_dict['arbe']['id']\n",
    "ids = sorted(map(int, ids))\n",
    "print(ids)\n",
    "arbe_loader[ids[0]][\"arbe\"]\n",
    "os.listdir(root_path)\n",
    "frames = range(0, 5, 1)\n",
    "print(frames)\n",
    "ids[frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "root_path = '/home/nesc525/drivers/4/p4tmesh/large4/6dwithgender/loss/corridor_test'\n",
    "j_loss = np.load(os.path.join(root_path, 'joints_loss.npy'))\n",
    "v_loss = np.load(os.path.join(root_path, 'vertices_loss.npy'))\n",
    "print((j_loss[0]+j_loss[1])/2)\n",
    "print((j_loss[-2]+j_loss[-1])/2)\n",
    "print((v_loss[0]+v_loss[1])/2)\n",
    "print((v_loss[-2]+v_loss[-1])/2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from message.dingtalk import TimerBot\n",
    "\n",
    "bot =TimerBot()\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1, 1, 1).plot([1,2,3], [1,2,3])\n",
    "fig.canvas.draw()\n",
    "img = cv2.cvtColor(np.asarray(fig.canvas.buffer_rgba()), cv2.COLOR_RGBA2BGR)\n",
    "bot.add_md(\"test\", \"【TEST】 \\n ![img]({})\".format(bot.img2b64(img)))\n",
    "bot.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(2, 2, 1, title=\"111\",ylim=(0,200)).plot([1,2,3], [1,2,3])\n",
    "fig.add_subplot(2, 2, 2, title=\"222\",ylim=(0,200)).plot([1,2,3], [1,2,3])\n",
    "fig.add_subplot(2, 2, 3, title=\"333\",ylim=(0,200)).plot([1,2,3], [1,2,3])\n",
    "fig.add_subplot(2, 2, 4, title=\"444\",ylim=(0,200)).plot([1,2,3], [1,2,3])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "q=q.view(batch_size*length_size, 9, 3, 3)\n",
    "q_blank=blank_atom.repeat(batch_size*length_size, 1, 1, 1)\n",
    "pose=torch.cat((q_blank,\n",
    "                q[:,1:3,:,:],\n",
    "                q_blank,\n",
    "                q[:,3:5,:,:],\n",
    "                q_blank.repeat(1,10,1,1),\n",
    "                q[:,5:9,:,:],\n",
    "                q_blank.repeat(1,4,1,1)), 1)\n",
    "rotmat=q[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def rot_mat_2_euler(R):\n",
    "    batch = R.size()[0]\n",
    "    sy = torch.sqrt(R[:,0,0]*R[:,0,0]+R[:,1,0]*R[:,1,0])\n",
    "    singular= sy<1e-6\n",
    "    singular=singular.float()\n",
    "        \n",
    "    x=torch.atan2(R[:,2,1], R[:,2,2])\n",
    "    y=torch.atan2(-R[:,2,0], sy)\n",
    "    z=torch.atan2(R[:,1,0],R[:,0,0])\n",
    "    \n",
    "    xs=torch.atan2(-R[:,1,2], R[:,1,1])\n",
    "    ys=torch.atan2(-R[:,2,0], sy)\n",
    "    zs=R[:,1,0]*0\n",
    "        \n",
    "    out_euler=torch.autograd.Variable(torch.zeros(batch,3).cuda())\n",
    "    out_euler[:,0]=x*(1-singular)+xs*singular\n",
    "    out_euler[:,1]=y*(1-singular)+ys*singular\n",
    "    out_euler[:,2]=z*(1-singular)+zs*singular\n",
    "    \n",
    "    return out_euler\n",
    "\n",
    "def euler_2_rot_mat(euler):\n",
    "\n",
    "    batch=euler.shape[0]\n",
    "        \n",
    "    c1=torch.cos(euler[:,0]).view(batch,1)#batch*1 \n",
    "    s1=torch.sin(euler[:,0]).view(batch,1)#batch*1 \n",
    "    c2=torch.cos(euler[:,2]).view(batch,1)#batch*1 \n",
    "    s2=torch.sin(euler[:,2]).view(batch,1)#batch*1 \n",
    "    c3=torch.cos(euler[:,1]).view(batch,1)#batch*1 \n",
    "    s3=torch.sin(euler[:,1]).view(batch,1)#batch*1 \n",
    "        \n",
    "    row1=torch.cat((c2*c3,          -s2,    c2*s3         ), 1).view(-1,1,3) #batch*1*3\n",
    "    row2=torch.cat((c1*s2*c3+s1*s3, c1*c2,  c1*s2*s3-s1*c3), 1).view(-1,1,3) #batch*1*3\n",
    "    row3=torch.cat((s1*s2*c3-c1*s3, s1*c2,  s1*s2*s3+c1*c3), 1).view(-1,1,3) #batch*1*3\n",
    "        \n",
    "    matrix = torch.cat((row1, row2, row3), 1) #batch*3*3\n",
    "     \n",
    "    return matrix\n",
    "\n",
    "def rotation6d_2_euler(nn_output):\n",
    "    batch_size = nn_output.size()[0]\n",
    "    num_joints = 9\n",
    "    blank_atom=torch.tensor([[1,0,0],[0,1,0],[0,0,1]], dtype=torch.float32, requires_grad=False, device=torch.device('cuda:0'))\n",
    "    q_blank=blank_atom.repeat(batch_size, 1, 1, 1)\n",
    "    pose = nn_output[:,3:num_joints*6+3].reshape(batch_size*num_joints, 6).contiguous()\n",
    "    tmp_x = nn.functional.normalize(pose[:,:3], dim = -1)\n",
    "    tmp_z = nn.functional.normalize(torch.cross(tmp_x, pose[:,3:], dim = -1), dim = -1)\n",
    "    tmp_y = torch.cross(tmp_z, tmp_x, dim = -1)\n",
    "\n",
    "    tmp_x = tmp_x.view(batch_size,num_joints, 3, 1)\n",
    "    tmp_y = tmp_y.view(batch_size,num_joints, 3, 1)\n",
    "    tmp_z = tmp_z.view(batch_size,num_joints, 3, 1)\n",
    "    pose = torch.cat((tmp_x, tmp_y, tmp_z), -1)\n",
    "    R=torch.cat((q_blank,\n",
    "                pose[:,1:3,:,:],\n",
    "                q_blank,\n",
    "                pose[:,3:5,:,:],\n",
    "                q_blank.repeat(1,10,1,1),\n",
    "                pose[:,5:9,:,:],\n",
    "                q_blank.repeat(1,4,1,1)), 1).view(batch_size*24,3,3)\n",
    "    rotmat=pose[:,0,:,:]\n",
    "\n",
    "    R = torch.rand(24, 3, 3)\n",
    "\n",
    "    euler = rot_mat_2_euler(R)\n",
    "    mat = rot_mat_2_euler(euler)\n",
    "    print(mat == R)\n",
    "    euler = euler.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = torch.rand(24, 3, 3)\n",
    "\n",
    "euler = rot_mat_2_euler(R)\n",
    "mat = rot_mat_2_euler(euler)\n",
    "print(mat == R)\n",
    "euler = euler.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "T = np.zeros((1,3), np.float32)\n",
    "a = (0.2,0.4,0.8)\n",
    "print (\"a\",a)\n",
    "R = cv2.Rodrigues(a)\n",
    "print (\"R[0]\", R[0])\n",
    "v3 = (R[0][2,1],R[0][0,2],R[0][1,0])\n",
    "print (\"v3\",v3)\n",
    "c = cv2.Rodrigues(v3)\n",
    "print (\"c[0]\",c[0])\n",
    "b = cv2.Rodrigues(R[0])\n",
    "print (\"b[0]\",b[0])\n",
    "p = (-2.100418,-2.167796,0.27330)\n",
    "print(cv2.Rodrigues(p)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_path = \"/home/nesc525/drivers/2\"\n",
    "target_path = \"/media/nesc525/perple/RGBD_data\"\n",
    "path = [p for p in os.listdir(root_path) if p[-1]=='T']\n",
    "for p in path:\n",
    "    os.system(\"cp -r {}/{}/rgbd_data {}/{}\".format(root_path,p,target_path,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "path = \"/home/nesc525/drivers/4/p4tmesh/new_test/loss\"\n",
    "# path = \"/home/nesc525/drivers/4/p4tdepth/RGBD/loss\"\n",
    "total_j = 0\n",
    "total_v = 0\n",
    "len_j = 0\n",
    "for p in os.listdir(path):\n",
    "    try:\n",
    "        j_loss = np.mean(np.load(os.path.join(path, p, 'per_joint_err.npy')), axis=1)\n",
    "        v_loss = np.mean(np.load(os.path.join(path, p, 'per_vetex_err.npy')),axis=1)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        continue\n",
    "    if p == 'test':\n",
    "        continue\n",
    "    print(\"s:\", p)\n",
    "\n",
    "    # print(\"max_j:\", np.max(j_loss))\n",
    "    # print(\"max_v:\", np.max(v_loss))\n",
    "    # print(\"mean_j:\",np.mean(j_loss))\n",
    "    # print(\"mean_v:\",np.mean(v_loss))\n",
    "    # print(\"var_j:\",np.var(j_loss))\n",
    "    print(\"var_v:\",np.var(v_loss)*100)\n",
    "    # print(\"len:\",len(j_loss))\n",
    "    total_j += np.sum(j_loss)\n",
    "    total_v += np.sum(v_loss)\n",
    "    len_j += len(j_loss)\n",
    "# print(total_j/len_j)\n",
    "# print(total_v/len_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"/home/nesc525/drivers/4/p4tdepth/depth\"\n",
    "# path = '/home/nesc525/drivers/4/p4tmesh/new_test'\n",
    "for p in os.listdir(path):\n",
    "    for t in os.listdir(path+\"/loss\"):\n",
    "        if p == t[0]:\n",
    "            os.system(\"cp -r {}/{}/loss/test/. {}/loss/{}\".format(path,p,path,t))\n",
    "            # os.system(\"rm -r {}/{}\".format(path,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "value = \"0.228/0.249&\t0.213/0.214&\t0.162/0.182&\t0.200/0.220&\t0.202/0.223&\t0.246/0.275&\t0.243/0.265&\t0.072/0.075\"\n",
    "value = list(map(lambda x: x.split('/'), value.split('&')))\n",
    "value = np.asarray(value, np.float32)\n",
    "for v in value:\n",
    "    print(v-value[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "t1 = torch.tensor([[1,2,3],[4,6,7]],dtype=float)\n",
    "t2 = torch.tensor([[2,3,4],[5,5,6]],dtype=float)\n",
    "print(F.mse_loss(t1, t2))\n",
    "print(torch.norm(t1-t2, dim=1))\n",
    "print(torch.mean(torch.norm(t1-t2, dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "s = np.load('/home/nesc525/drivers/1/2021-10-17_15-01-24_E/optitrack/id=1_st=1634454156.566333.npz')\n",
    "print(s['markers'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/home/nesc525/drivers/1/2021-10-17_15-01-24_E/offsets.txt'), \"r\") as f:\n",
    "    offset_dict = eval(f.readline())\n",
    "    base = f.readline()\n",
    "offset_dict['optitrack']\n",
    "# base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "s = np.load('/home/nesc525/drivers/2/2022-03-25_14-35-54/optitrack/id=3139_st=1648190232.866333.npz')\n",
    "print(dict(s).keys())\n",
    "print(s['markers'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from calib.utils import to_radar_transform_mat\n",
    "trans = to_radar_transform_mat('/home/nesc525/drivers/1/2021-10-18_10-10-23_E')\n",
    "rot_mat = cv2.Rodrigues(s['pose'][3:6])\n",
    "print(cv2.Rodrigues(rot_mat[0])[0].shape)\n",
    "a = np.array([2,5,6])\n",
    "print(a.shape)\n",
    "print(a @ rot_mat[0].T)\n",
    "print(rot_mat[0] @ a)\n",
    "print(a @ rot_mat[0].T + trans['optitrack']['t'])\n",
    "print(rot_mat[0] @ a + trans['optitrack']['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "path = '/home/nesc525/drivers/1/2021-10-18_18-21-24_E/pkl'\n",
    "a = []\n",
    "f_list = os.listdir(path)\n",
    "f_list.sort(key=lambda x: int(x[3:-4]))\n",
    "for p in f_list:\n",
    "    t_s = time.time()\n",
    "\n",
    "    with open(os.path.join(path, p), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    a.append(data)\n",
    "    t_e = time.time()\n",
    "    print(t_e - t_s)\n",
    "a[1]['arbe'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/nesc525/drivers/1/2021-10-23_21-03-26_M/pkl/id=144.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    print(data['arbe'])\n",
    "data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.p4t.datasets.folder_list import *\n",
    "import os\n",
    "path = []\n",
    "driver_paths = ['/home/nesc525/drivers/1','/home/nesc525/drivers/2','/home/nesc525/drivers/3']\n",
    "for pa in TRAIN_DIRS:\n",
    "    path.append(pa)\n",
    "for v in SELECTED_DIRS.values():\n",
    "    path.append(v)\n",
    "print(path)\n",
    "for driver_path in driver_paths:\n",
    "    for p in os.listdir(driver_path):\n",
    "        if p not in path and os.path.exists(os.path.join(driver_path,p,'pkl_data/data.pkl')):\n",
    "            print(driver_path, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dataloader.result_loader import ResultFileLoader\n",
    "from minimal.bridge import JointsBridge\n",
    "from visualization.utils import o3d_plot, o3d_pcl\n",
    "\n",
    "driver_paths = ['/home/nesc525/drivers/1','/home/nesc525/drivers/2','/home/nesc525/drivers/3']\n",
    "folders = ['2022-03-30_22-39-49_M']\n",
    "for driver_path in driver_paths:\n",
    "    for p in os.listdir(driver_path):\n",
    "        if p in folders:\n",
    "            root_path = os.path.join(driver_path, p)\n",
    "res_loader = ResultFileLoader(root_path=root_path, enabled_sources=[\"arbe\",\"master\",\"sub2\",\"kinect_skeleton\",\"kinect_pcl\",\"kinect_pcl_remove_zeros\", \"optitrack\",\"mesh\",\"mosh\",\"mesh_param\"])\n",
    "for frame, _ in res_loader:\n",
    "    bridge = JointsBridge()\n",
    "    bridge.init_input(frame['master_skeleton'], frame['master_pcl'])\n",
    "    k_jnts, pcl = bridge.map(\"kinect\")\n",
    "    joint_error = np.linalg.norm((k_jnts[:22] - frame['mesh_param']['joints'][:22]))\n",
    "    o3d_plot([o3d_pcl(frame['master_pcl'], [0,1,0]), o3d_pcl(frame['master_skeleton'], [0,0,0]), o3d_pcl(k_jnts[:22], [1,0,0]), o3d_pcl(frame['mesh_param']['joints'][:22], [0,0,1])])\n",
    "    print(joint_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "for test in ['lab1','lab2','furnished','rain','poor_lighting',]: #'smoke',\n",
    "    f_name = os.path.join('/home/nesc525/drivers/4/p4t_mosh/mmWave/female', test, 'shape_err.npy')\n",
    "    target_path = os.path.join('/home/nesc525/drivers/4/p4t_mosh/mmWave/shape_err', test)\n",
    "    t_list = os.listdir(target_path)\n",
    "    for p in t_list:\n",
    "        if 'F' in p:\n",
    "            shutil.copyfile(f_name, os.path.join(target_path, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.utils import o3d_mesh\n",
    "from mosh.utils import mosh_param_parser\n",
    "import numpy as np\n",
    "\n",
    "param = np.load('/home/nesc525/drivers/2/2022-03-29_11-50-15_F/mosh/param/id=0_st=1648525797.838.npz')\n",
    "param\n",
    "# mosh_param_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.p4t.datasets.folder_list import SELECTED_DIRS\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "beta = np.load('ignoredata/shape.npy')\n",
    "average = np.mean(beta, 0)\n",
    "num_frame = beta.shape[0]\n",
    "print(beta.shape)\n",
    "error = np.mean(np.square(np.repeat(average, num_frame).reshape(-1, 16) - beta), 0)\n",
    "# err = np.linalg.norm((np.repeat(average, num_frame).reshape(-1, 16) - beta), axis=0)\n",
    "# print(err**2/num_frame)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.repeat(average, num_frame, 0).shape\n",
    "# beta.shape\n",
    "print(beta[:2])\n",
    "print(average)\n",
    "print(np.linalg.norm((np.repeat(average, 2).reshape(-1, 16), beta[:2]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "from nn.p4t.datasets.mm_dataset import Depth\n",
    "\n",
    "dataset = Depth('/home/nesc525/drivers/2', train=False, use_pkl=False, create_pkl=False)\n",
    "t1 = time.time()\n",
    "for i in range(5):\n",
    "    # dataset[1]\n",
    "    with open('/home/nesc525/drivers/1/2021-10-18_09-48-31_M/pkl/id=0_st=1634521727.9382143_dt=1634521727.938222.pkl', 'rb') as f:\n",
    "    # with open('/home/nesc525/drivers/3/2022-03-30_20-49-18_M/pkl/id=3_st=1648644691.1595914_dt=1648644691.0662491.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    a = data[0].keys()\n",
    "    print(a)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[[1,2],[3,4],[3,4]], [[7,8],[0,9],[3,4]]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.Tensor([[1,2],[3,4]])\n",
    "b = b.unsqueeze(-2).repeat(1,3,1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "for i in range(5):\n",
    "    ts = time.time()\n",
    "    with open('/home/nesc525/drivers/3/2022-03-30_20-49-18_M/pkl/id=8_st=1648644691.2760816_dt=1648644691.2832491.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(time.time() - ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.zeros([2,3,1024,2048])\n",
    "a[0,:,255,1023] = torch.ones_like(a[0,:,255,1023])\n",
    "a[0,:,1023,2047] = torch.ones_like(a[0,:,256,1024])\n",
    "print(a[0,:,255,1023])\n",
    "b = torch.ones([2,1024,1,2],dtype=torch.float32)\n",
    "b[0,0,0,:] = torch.tensor([-0.0009765625, -0.5014662756598240469208211143695])\n",
    "c = torch.nn.functional.grid_sample(a, b)\n",
    "print(c.permute(3,0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    " \n",
    "z = zipfile.ZipFile(\"/home/nesc525/drivers/0/chen/dataset.zip\", \"r\")\n",
    "\n",
    "files = []\n",
    "for filename in z.namelist():\n",
    "    if filename.endswith('md'):\n",
    "        files.append(filename)\n",
    "        print('File:', filename)\n",
    "content = z.read(files[-2])\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '[1,2,3, 4]'\n",
    "b = eval(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "l = nn.Conv1d(512, 1024, (1, 1))\n",
    "a = torch.ones(32,512,7,7)\n",
    "b = l(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([1.0])\n",
    "# np.float32(a)\n",
    "a.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sync.offsets import CalibOffsets\n",
    "\n",
    "root_path = ''\n",
    "CalibOffsets.from_file(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataloader.result_loader import ResultFileLoader\n",
    "\n",
    "enabled_sources = 'arbe,optitrack,sub2,kinect_pcl,kinect_pcl_remove_zeros,mesh,mosh,mesh_obj'.split(',')\n",
    "path = '/home/nesc525/drivers/2/2021-10-20_14-08-40_F'\n",
    "skip_head = 0\n",
    "skip_tail = 0\n",
    "data_loader = ResultFileLoader(root_path=path, skip_head=skip_head, skip_tail=skip_tail, enabled_sources=enabled_sources)\n",
    "for i in range(len(data_loader)):\n",
    "    frame, _ = data_loader[i]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1427, 1348],\n",
       "         [1588, 1671]]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from nn.datasets.utils import project_pcl_torch\n",
    "\n",
    "pcl = np.array([[[1,2,3], [4,5,6]]])\n",
    "project_pcl_torch(torch.from_numpy(pcl).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1024, 2048), (2048, 2048), (2048, 1024)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = [2048] * (3 - 1)\n",
    "\n",
    "[(n, k) for n, k in zip([1024] + h, h + [1024])]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f576c85a870e21dafa7d052349fbe7d8c7d7362a9c2cf3d3f84ed8b88c87d603"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('3DSVC': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
